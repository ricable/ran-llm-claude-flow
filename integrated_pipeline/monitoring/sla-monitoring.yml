# SLA Monitoring Configuration for RAN LLM Claude Flow
# Production SLA Targets: 25+ docs/hour, <100μs IPC latency, >0.75 quality score

sla_targets:
  # Document Processing SLA
  document_throughput:
    metric: "rate(documents_processed_total[5m]) * 3600"
    target: 25
    operator: ">="
    unit: "docs/hour"
    severity: "critical"
    description: "Document processing throughput must exceed 25 documents per hour"
    alert_threshold: 20  # Alert if below 20 docs/hour
    measurement_window: "5m"
    
  # IPC Latency SLA
  ipc_latency:
    metric: "histogram_quantile(0.95, rate(ipc_latency_seconds_bucket[30s]))"
    target: 0.0001  # 100 microseconds
    operator: "<="
    unit: "seconds"
    severity: "warning"
    description: "P95 IPC latency must be under 100 microseconds"
    alert_threshold: 0.00008  # Alert if above 80μs
    measurement_window: "30s"
    
  # Quality Score SLA
  quality_score:
    metric: "avg_over_time(document_quality_score[10m])"
    target: 0.75
    operator: ">="
    unit: "score"
    severity: "warning"
    description: "Document quality score must exceed 0.75"
    alert_threshold: 0.7  # Alert if below 0.7
    measurement_window: "10m"
    
  # Memory Utilization SLA (128GB M3 Max)
  memory_utilization:
    metric: "(rust_core_memory_bytes + python_ml_memory_bytes + shared_memory_used_bytes + monitoring_memory_bytes) / (128 * 1024^3)"
    target: 0.95
    operator: "<="
    unit: "percentage"
    severity: "critical"
    description: "Total memory utilization must not exceed 95% of 128GB"
    alert_threshold: 0.9  # Alert if above 90%
    measurement_window: "1m"
    
  # Monitoring Overhead SLA
  monitoring_overhead:
    metric: "monitoring_overhead_percentage"
    target: 1.0
    operator: "<="
    unit: "percentage"
    severity: "warning"
    description: "Monitoring system overhead must not exceed 1%"
    alert_threshold: 0.8  # Alert if above 0.8%
    measurement_window: "2m"
    
  # System Availability SLA
  component_availability:
    metrics:
      rust_core: "up{job='rust-core'}"
      python_ml: "up{job='python-ml'}"
      ipc_protocol: "up{job='ipc-protocol'}"
      mcp_server: "up{job='mcp-server'}"
    target: 1.0
    operator: "=="
    unit: "boolean"
    severity: "critical"
    description: "All system components must be available"
    measurement_window: "30s"
    
  # Neural Model Performance SLA
  neural_model_confidence:
    metric: "avg_over_time(neural_model_confidence[15m])"
    target: 0.85
    operator: ">="
    unit: "confidence"
    severity: "info"
    description: "Neural model confidence should exceed 0.85"
    alert_threshold: 0.8  # Alert if below 0.8
    measurement_window: "15m"
    
  # Bottleneck Detection SLA
  bottleneck_severity:
    metric: "max(bottleneck_severity_score)"
    target: 0.7
    operator: "<="
    unit: "severity"
    severity: "warning"
    description: "Bottleneck severity should not exceed 0.7"
    alert_threshold: 0.6  # Alert if above 0.6
    measurement_window: "2m"

# SLA Reporting Configuration
reporting:
  # Daily SLA Report
  daily_report:
    enabled: true
    time: "06:00"
    timezone: "UTC"
    recipients:
      - "devops-team@company.com"
      - "performance-team@company.com"
    format: "json"
    include_trends: true
    
  # Weekly SLA Summary
  weekly_report:
    enabled: true
    day: "monday"
    time: "09:00"
    timezone: "UTC"
    recipients:
      - "engineering-leads@company.com"
      - "product-team@company.com"
    format: "html"
    include_recommendations: true
    
  # Real-time SLA Dashboard
  dashboard:
    enabled: true
    refresh_interval: "5s"
    public_url: "http://monitoring.company.com/sla-dashboard"
    auth_required: false  # Internal network only
    
# SLA Breach Response
incident_response:
  # Automatic escalation rules
  escalation:
    level_1:  # 0-5 minutes
      notify:
        - "on-call-engineer@company.com"
        - "slack://performance-alerts"
      actions:
        - "trigger_auto_scaling"
        - "increase_monitoring_frequency"
        
    level_2:  # 5-15 minutes
      notify:
        - "engineering-manager@company.com"
        - "pagerduty://performance-team"
      actions:
        - "trigger_performance_optimization"
        - "collect_detailed_metrics"
        
    level_3:  # 15+ minutes
      notify:
        - "cto@company.com"
        - "incident-commander@company.com"
      actions:
        - "initiate_incident_response"
        - "prepare_status_page_update"
        
  # Automatic remediation
  auto_remediation:
    enabled: true
    actions:
      # High memory usage
      memory_pressure:
        trigger: "memory_utilization >= 0.9"
        actions:
          - "garbage_collect"
          - "increase_shared_memory_pool"
          - "optimize_model_caching"
          
      # High IPC latency
      ipc_latency_high:
        trigger: "ipc_latency > 0.00015"  # 150μs
        actions:
          - "restart_ipc_connections"
          - "switch_to_backup_communication"
          - "reduce_message_frequency"
          
      # Low throughput
      throughput_degradation:
        trigger: "document_throughput < 20"
        actions:
          - "increase_worker_threads"
          - "switch_to_smaller_model"
          - "bypass_quality_checks_temporarily"
          
# SLA Calculation Methods
calculation:
  # Availability calculation
  availability:
    method: "time_based"
    exclude_maintenance_windows: true
    rolling_window: "30d"
    target: 99.9  # 99.9% uptime
    
  # Performance calculation
  performance:
    method: "weighted_average"
    weights:
      document_throughput: 0.4
      ipc_latency: 0.3
      quality_score: 0.2
      monitoring_overhead: 0.1
    rolling_window: "7d"
    
  # Quality calculation
  quality:
    method: "p95_percentile"
    exclude_outliers: true
    outlier_threshold: 3  # 3 standard deviations
    rolling_window: "24h"
    
# Integration with External Systems
integrations:
  # Prometheus AlertManager
  alertmanager:
    enabled: true
    webhook_url: "http://alertmanager:9093/api/v1/alerts"
    
  # Grafana Annotations
  grafana:
    enabled: true
    api_url: "http://grafana:3000/api/annotations"
    api_key: "${GRAFANA_API_KEY}"
    
  # PagerDuty Integration
  pagerduty:
    enabled: true
    integration_key: "${PAGERDUTY_INTEGRATION_KEY}"
    service_key: "${PAGERDUTY_SERVICE_KEY}"
    
  # Slack Notifications
  slack:
    enabled: true
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#performance-alerts"
    mention_on_breach: true
    
# Historical SLA Data
historical_data:
  retention_period: "1y"
  storage_backend: "prometheus"
  backup_enabled: true
  backup_frequency: "daily"
  backup_location: "s3://sla-backups/ran-llm-claude-flow/"
  
# Custom SLA Metrics
custom_metrics:
  # End-to-end processing time
  e2e_processing_time:
    query: "histogram_quantile(0.95, rate(document_e2e_processing_duration_seconds_bucket[5m]))"
    target: 30  # 30 seconds max
    description: "End-to-end document processing time (input to output)"
    
  # Model switching efficiency
  model_switching_efficiency:
    query: "rate(successful_model_switches_total[10m]) / rate(attempted_model_switches_total[10m])"
    target: 0.95  # 95% success rate
    description: "Success rate of dynamic model switching"
    
  # Zero-copy operation ratio
  zero_copy_ratio:
    query: "rate(zero_copy_operations_total[5m]) / rate(total_memory_operations_total[5m])"
    target: 0.9  # 90% zero-copy operations
    description: "Percentage of memory operations using zero-copy"
    
  # Adaptive optimization effectiveness
  optimization_effectiveness:
    query: "avg_over_time(optimization_effectiveness_score[1h])"
    target: 0.8  # 80% effectiveness
    description: "Average effectiveness of applied optimizations"